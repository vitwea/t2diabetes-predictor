{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) - Diabetes Dataset\n",
    "## Comprehensive analysis to understand data distribution, missing values, correlations, and class differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m plt.rcParams[\u001b[33m'\u001b[39m\u001b[33mfigure.figsize\u001b[39m\u001b[33m'\u001b[39m] = (\u001b[32m12\u001b[39m, \u001b[32m6\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Load the dataset from parquet file\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataset loaded successfully\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\Desktop\\t2diabetes-predictor\\venv\\Lib\\site-packages\\pandas\\io\\parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\Desktop\\t2diabetes-predictor\\venv\\Lib\\site-packages\\pandas\\io\\parquet.py:258\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    257\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    265\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    266\u001b[39m         path_or_handle,\n\u001b[32m    267\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         **kwargs,\n\u001b[32m    271\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\Desktop\\t2diabetes-predictor\\venv\\Lib\\site-packages\\pandas\\io\\parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\Desktop\\t2diabetes-predictor\\venv\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'dataset.parquet'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Load the dataset from parquet file\n",
    "df = pd.read_parquet('./data/final/nhanes_diabetes.parquet')\n",
    "\n",
    "print(\"Dataset loaded successfully\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. General Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display general information about the dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"GENERAL DATASET INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Dimensions and basic info\n",
    "print(f\"\\nDimensions: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "print(f\"\\nMemory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Display first rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Display last rows\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze missing values across all features\n",
    "print(\"=\" * 80)\n",
    "print(\"MISSING DATA ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Count missing values per column\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': missing_data.values,\n",
    "    'Missing_Percentage': missing_percent.values\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "display(missing_df[missing_df['Missing_Count'] > 0])\n",
    "\n",
    "# Visualize missing data if any exists\n",
    "if missing_data.sum() > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_df_sorted = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=True)\n",
    "    plt.barh(missing_df_sorted['Column'], missing_df_sorted['Missing_Percentage'], color='coral')\n",
    "    plt.xlabel('Percentage of Missing Data (%)')\n",
    "    plt.title('Distribution of Missing Values by Variable')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n✓ No missing data found in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Variable Analysis (Diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the diabetes target variable\n",
    "print(\"=\" * 80)\n",
    "print(\"TARGET VARIABLE ANALYSIS: DIABETES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define target column name - ADJUST IF YOUR COLUMN NAME IS DIFFERENT\n",
    "target_col = 'diabetes'  # CHANGE THIS IF NEEDED\n",
    "\n",
    "# Examine unique values\n",
    "print(f\"\\nUnique values in '{target_col}':\")\n",
    "print(df[target_col].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nDistribution (%):\")\n",
    "print((df[target_col].value_counts(normalize=True) * 100).sort_index())\n",
    "\n",
    "# Filter to keep only positive (1) and negative (2) cases\n",
    "print(f\"\\nTotal records before filtering: {len(df)}\")\n",
    "df_filtered = df[df[target_col].isin([1, 2])].copy()\n",
    "print(f\"Records after filtering only diabetes (1, 2): {len(df_filtered)}\")\n",
    "print(f\"Records removed: {len(df) - len(df_filtered)}\")\n",
    "\n",
    "# Update dataframe with filtered data\n",
    "df = df_filtered\n",
    "\n",
    "# Display class distribution after filtering\n",
    "print(f\"\\nClass distribution after filtering:\")\n",
    "class_dist = df[target_col].value_counts().sort_index()\n",
    "print(class_dist)\n",
    "\n",
    "# Visualize target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Bar chart - absolute frequency\n",
    "class_dist.plot(kind='bar', ax=axes[0], color=['skyblue', 'salmon'])\n",
    "axes[0].set_title('Diabetes Distribution (Absolute Frequency)')\n",
    "axes[0].set_xlabel('Diabetes Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# Pie chart - percentage\n",
    "class_dist.plot(kind='pie', ax=axes[1], autopct='%1.1f%%', colors=['skyblue', 'salmon'])\n",
    "axes[1].set_title('Diabetes Distribution (Percentage)')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display class imbalance ratio\n",
    "imbalance_ratio = class_dist.max() / class_dist.min()\n",
    "print(f\"\\nImbalance ratio: {imbalance_ratio:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descriptive Statistics for Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute descriptive statistics for all numeric features\n",
    "print(\"=\" * 80)\n",
    "print(\"DESCRIPTIVE STATISTICS - NUMERIC VARIABLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select numeric columns (excluding target variable)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if target_col in numeric_cols:\n",
    "    numeric_cols.remove(target_col)\n",
    "\n",
    "print(f\"\\nNumeric variables found: {len(numeric_cols)}\")\n",
    "print(f\"Columns: {numeric_cols}\\n\")\n",
    "\n",
    "# Calculate comprehensive descriptive statistics\n",
    "desc_stats = df[numeric_cols].describe().T\n",
    "desc_stats['variance'] = df[numeric_cols].var()\n",
    "desc_stats['skewness'] = df[numeric_cols].skew()\n",
    "desc_stats['kurtosis'] = df[numeric_cols].kurtosis()\n",
    "\n",
    "print(\"\\nComprehensive descriptive statistics:\")\n",
    "display(desc_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Distribution of Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions of all numeric variables using histograms\n",
    "print(\"\\nDistributions of Numeric Variables:\")\n",
    "\n",
    "n_cols = len(numeric_cols)\n",
    "n_rows = (n_cols + 2) // 3\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, 3, figsize=(15, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Create histogram for each numeric variable\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    axes[idx].hist(df[col].dropna(), bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribution: {col}')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    # Add mean line\n",
    "    axes[idx].axvline(df[col].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[col].mean():.2f}')\n",
    "    axes[idx].legend()\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(n_cols, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using the Interquartile Range (IQR) method\n",
    "print(\"=\" * 80)\n",
    "print(\"OUTLIER DETECTION (IQR Method)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "outliers_summary = {}\n",
    "\n",
    "# Calculate IQR bounds for each numeric variable\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define outlier bounds (1.5 * IQR is standard)\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    outliers_summary[col] = {\n",
    "        'count': len(outliers),\n",
    "        'percent': (len(outliers) / len(df)) * 100,\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound\n",
    "    }\n",
    "\n",
    "outliers_df = pd.DataFrame(outliers_summary).T.sort_values('count', ascending=False)\n",
    "print(\"\\nOutliers detected (IQR * 1.5):\")\n",
    "display(outliers_df[outliers_df['count'] > 0])\n",
    "\n",
    "# Visualize outliers using boxplots\n",
    "fig, axes = plt.subplots(n_rows, 3, figsize=(15, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    axes[idx].boxplot(df[col].dropna())\n",
    "    axes[idx].set_title(f'Boxplot: {col}')\n",
    "    axes[idx].set_ylabel(col)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(n_cols, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlations between variables and with target\n",
    "print(\"=\" * 80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = df[numeric_cols + [target_col]].corr()\n",
    "\n",
    "# Display correlations with target variable\n",
    "print(\"\\nCorrelation with target variable (Diabetes):\")\n",
    "target_corr = correlation_matrix[target_col].drop(target_col).sort_values(ascending=False)\n",
    "print(target_corr)\n",
    "\n",
    "# Visualize full correlation matrix as heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.2f', square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix - All Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize only correlations with target variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "target_corr_sorted = target_corr.sort_values()\n",
    "colors = ['red' if x < 0 else 'green' for x in target_corr_sorted.values]\n",
    "plt.barh(range(len(target_corr_sorted)), target_corr_sorted.values, color=colors, alpha=0.7)\n",
    "plt.yticks(range(len(target_corr_sorted)), target_corr_sorted.index)\n",
    "plt.xlabel('Correlation with Diabetes')\n",
    "plt.title('Feature Correlation with Target Variable')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analysis by Class (Diabetes vs. Non-Diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare statistics between diabetes classes\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPARISON BETWEEN DIABETES CLASSES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Display descriptive statistics grouped by class\n",
    "print(\"\\nDescriptive statistics by class:\")\n",
    "grouped_stats = df.groupby(target_col)[numeric_cols].describe().T\n",
    "display(grouped_stats)\n",
    "\n",
    "# Compare mean values between groups\n",
    "print(\"\\nComparison of means by class:\")\n",
    "comparison = df.groupby(target_col)[numeric_cols].mean()\n",
    "display(comparison)\n",
    "\n",
    "# Visualize differences using boxplots by class\n",
    "fig, axes = plt.subplots(n_rows, 3, figsize=(15, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    df.boxplot(column=col, by=target_col, ax=axes[idx])\n",
    "    axes[idx].set_title(f'{col} by Diabetes Class')\n",
    "    axes[idx].set_xlabel('Diabetes')\n",
    "    axes[idx].set_ylabel(col)\n",
    "    plt.sca(axes[idx])\n",
    "    plt.xticks([1, 2], ['No (1)', 'Yes (2)'])\n",
    "\n",
    "# Remove the default title\n",
    "plt.suptitle('')\n",
    "# Hide empty subplots\n",
    "for idx in range(n_cols, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Statistical Tests (Group Differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-tests to identify significant differences between groups\n",
    "print(\"=\" * 80)\n",
    "print(\"STUDENT'S T-TEST - Difference Between Groups\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Separate data by class\n",
    "group_1 = df[df[target_col] == 1][numeric_cols]\n",
    "group_2 = df[df[target_col] == 2][numeric_cols]\n",
    "\n",
    "# Perform t-test for each variable\n",
    "print(\"\\nStudent's t-test (H0: means are equal):\")\n",
    "t_test_results = {}\n",
    "\n",
    "for col in numeric_cols:\n",
    "    t_stat, p_value = stats.ttest_ind(group_1[col].dropna(), group_2[col].dropna())\n",
    "    t_test_results[col] = {'t_statistic': t_stat, 'p_value': p_value}\n",
    "\n",
    "t_test_df = pd.DataFrame(t_test_results).T.sort_values('p_value')\n",
    "t_test_df['Significant (α=0.05)'] = t_test_df['p_value'] < 0.05\n",
    "\n",
    "print(\"\\nT-test results (sorted by p-value):\")\n",
    "display(t_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Categorical Variables Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical variables if any exist\n",
    "print(\"=\" * 80)\n",
    "print(\"CATEGORICAL VARIABLES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "if categorical_cols:\n",
    "    print(f\"\\nCategorical variables found: {len(categorical_cols)}\")\n",
    "    print(f\"Columns: {categorical_cols}\\n\")\n",
    "    \n",
    "    # Display value counts for each categorical variable\n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"Unique values: {df[col].nunique()}\")\n",
    "        print(df[col].value_counts())\n",
    "else:\n",
    "    print(\"\\nNo categorical variables found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. EDA Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive EDA summary report\n",
    "print(\"=\" * 80)\n",
    "print(\"EDA SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create summary report with key findings\n",
    "summary_report = f\"\"\"\n",
    "DIMENSIONS AND STRUCTURE:\n",
    "  • Total records: {len(df):,}\n",
    "  • Total variables: {df.shape[1]}\n",
    "  • Numeric variables: {len(numeric_cols)}\n",
    "  • Categorical variables: {len(categorical_cols)}\n",
    "\n",
    "MISSING DATA:\n",
    "  • Total percentage of missing data: {(df.isnull().sum().sum() / (len(df) * df.shape[1])) * 100:.2f}%\n",
    "  • Columns with missing values: {missing_data.sum()}\n",
    "\n",
    "TARGET VARIABLE (Diabetes):\n",
    "  • Class 1 (No Diabetes): {class_dist.get(1, 0):,} records ({(class_dist.get(1, 0)/len(df)*100):.1f}%)\n",
    "  • Class 2 (Yes Diabetes): {class_dist.get(2, 0):,} records ({(class_dist.get(2, 0)/len(df)*100):.1f}%)\n",
    "  • Imbalance ratio: {imbalance_ratio:.2f}:1\n",
    "\n",
    "OUTLIERS:\n",
    "  • Variables with outliers: {sum(1 for x in outliers_df['count'] if x > 0)}\n",
    "  • Total outliers detected: {outliers_df['count'].sum():.0f}\n",
    "\n",
    "CORRELATION:\n",
    "  • Top 5 variables most correlated with Diabetes:\n",
    "{target_corr.head(5).to_string()}\n",
    "\"\"\"\n",
    "\n",
    "print(summary_report)\n",
    "\n",
    "# Save summary report to file\n",
    "with open('eda_summary_report.txt', 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(\"\\n✓ Report saved to 'eda_summary_report.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Notes\n",
    "\n",
    "1. **Adjust target variable name**: If your diabetes column has a different name, update `target_col` in section 4.\n",
    "\n",
    "2. **Handling missing data**: Based on the results, you can:\n",
    "   - Remove records with too many missing values\n",
    "   - Impute with mean/median\n",
    "   - Use advanced techniques (KNN, iterative imputer)\n",
    "\n",
    "3. **Outliers**: Do not automatically remove them. Analyze whether they are errors or legitimate values.\n",
    "\n",
    "4. **Class imbalance**: If significant imbalance exists, consider:\n",
    "   - Oversampling (SMOTE)\n",
    "   - Undersampling\n",
    "   - Class weights in models\n",
    "\n",
    "5. **Next steps**:\n",
    "   - Feature engineering\n",
    "   - Feature selection\n",
    "   - Normalization/Scaling\n",
    "   - Predictive modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
